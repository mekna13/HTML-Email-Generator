# app/services/scraper.py
import json
import datetime
import time
import re
from datetime import date
from typing import Dict, List, Any, Optional, Tuple
import logging

# Selenium imports
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from dateutil.parser import parse

# Get logger
logger = logging.getLogger("tamu_newsletter")

class EventScraper:
    """
    Service class to handle event scraping functionality
    """
    
    def __init__(self):
        """Initialize the event scraper"""
        self.cte_url = "https://calendar.tamu.edu/cte/all"
        self.elp_url = "https://calendar.tamu.edu/elp/all"
    
    def scrape_events(self, start_date: date, end_date: date, debug_mode: bool = False) -> Tuple[bool, Dict[str, Any]]:
        """
        Scrape events from TAMU calendars
        
        Args:
            start_date: Start date for event range
            end_date: End date for event range
            debug_mode: Whether to run in debug mode (ignored now - always runs directly)
            
        Returns:
            Tuple of (success, events_data)
        """
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
        
        logger.info(f"Starting scraping for date range: {start_date_str} to {end_date_str}")
        
        # Always run directly now - no subprocess needed
        return self._scrape_direct(start_date, end_date)
    
    def _scrape_direct(self, start_date: date, end_date: date) -> Tuple[bool, Dict[str, Any]]:
        """
        Run scraping directly with integrated functionality
        
        Args:
            start_date: Start date for event range
            end_date: End date for event range
            
        Returns:
            Tuple of (success, events_data)
        """
        logger.info("Running scraping directly with integrated functionality")
        
        try:
            # Scrape CTE events
            logger.info(f"Scraping CTE events from {self.cte_url}")
            cte_events = []
            try:
                cte_events = self._scrape_events_from_url(self.cte_url, start_date, end_date)
                logger.info(f"Found {len(cte_events)} CTE events")
            except Exception as e:
                logger.error(f"Error scraping CTE events: {str(e)}")
                return (False, {"error": f"Error scraping CTE events: {str(e)}"})
            
            # Scrape ELP events
            logger.info(f"Scraping ELP events from {self.elp_url}")
            elp_events = []
            try:
                elp_events = self._scrape_events_from_url(self.elp_url, start_date, end_date)
                logger.info(f"Found {len(elp_events)} ELP events")
            except Exception as e:
                logger.error(f"Error scraping ELP events: {str(e)}")
                return (False, {"error": f"Error scraping ELP events: {str(e)}"})
            
            # Prepare and save the data
            events_data = {
                "date_range": {
                    "start_date": start_date.strftime('%Y-%m-%d'),
                    "end_date": end_date.strftime('%Y-%m-%d')
                },
                "cte_events": cte_events,
                "elp_events": elp_events
            }
            
            # Save data to file
            try:
                logger.info("Saving data to events.json")
                with open("events.json", "w", encoding="utf-8") as f:
                    json.dump(events_data, f, indent=2)
            except Exception as e:
                logger.error(f"Error saving events data to file: {str(e)}")
                return (False, {"error": f"Error saving events data: {str(e)}"})
            
            logger.info("Direct scraping completed successfully")
            return (True, events_data)
            
        except Exception as e:
            logger.error(f"Error during scraping: {str(e)}")
            return (False, {"error": f"Error during scraping: {str(e)}"})
    
    def _is_within_date_range(self, event_date: str, start_date: date, end_date: date) -> bool:
        """Check if event_date is within the given range"""
        try:
            # Parse the event date
            event_date_obj = parse(event_date, fuzzy=True)
            
            # Compare with start and end dates
            return start_date <= event_date_obj.date() <= end_date
        except:
            # If there's an error in parsing, include the event to be safe
            logger.warning(f"Could not parse date '{event_date}', including event anyway")
            return False
    

        # Update this section in your _scrape_events_from_url method

   # Update your _scrape_events_from_url method with better error handling

    def _scrape_events_from_url(self, url: str, start_date: date, end_date: date) -> List[Dict[str, Any]]:
        """Scrape events from a specified URL within the date range"""
        
        # ... existing Chrome setup code ...
        try:
            logger.info(f"Successfully initialized Chrome driver, loading: {url}")
            
            # Load the page
            driver.get(url)
            logger.info("Page loaded successfully")
            
            # Wait for events to load with better error handling
            try:
                WebDriverWait(driver, 30).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "lw_cal_event"))
                )
                logger.info("Events container found")
            except TimeoutException:
                logger.warning("Timeout waiting for events to load")
                # Check if page loaded at all
                page_title = driver.title
                logger.info(f"Page title: {page_title}")
                # Return empty list instead of failing
                return []
            
            # Add a small delay
            time.sleep(2)
            
            # Find event elements with error checking
            event_elements = driver.find_elements(By.CLASS_NAME, "lw_cal_event")
            
            # DEBUG: Check if event_elements is None
            if event_elements is None:
                logger.error("event_elements is None - this shouldn't happen with Selenium")
                return []
            
            logger.info(f"Found {len(event_elements)} event elements")
            
            # If no events found, check page content
            if len(event_elements) == 0:
                logger.warning("No events found on page")
                # Debug: check page source
                page_source = driver.page_source
                logger.info(f"Page source length: {len(page_source) if page_source else 'None'}")
                if page_source and "lw_cal_event" in page_source:
                    logger.warning("Events exist in source but not found by selector")
                return []
            
            # Process events with better error handling
            event_data = []
            
            for i, element in enumerate(event_elements):
                try:
                    logger.info(f"Processing event {i+1}/{len(event_elements)}")
                    
                    # Extract event details with None checks
                    title_elements = element.find_elements(By.CSS_SELECTOR, "h4 a")
                    if not title_elements:
                        logger.warning(f"No title found for event {i+1}")
                        continue
                    
                    title_element = title_elements[0]
                    event_name = title_element.text
                    event_link = title_element.get_attribute("href")
                    
                    if not event_name:
                        logger.warning(f"Empty event name for event {i+1}")
                        continue
                    
                    # Get date/time with None check
                    date_time_elements = element.find_elements(By.CLASS_NAME, "date-time")
                    if date_time_elements:
                        date_time = date_time_elements[0].text
                        if date_time:  # Check if not None/empty
                            event_date = date_time.split("路")[0].strip() if "路" in date_time else date_time
                            event_time = date_time.split("路")[1].strip() if "路" in date_time else ""
                        else:
                            logger.warning(f"Empty date_time for event: {event_name}")
                            event_date = ""
                            event_time = ""
                    else:
                        logger.warning(f"No date-time element for event: {event_name}")
                        event_date = ""
                        event_time = ""
                    
                    # Check if event is within date range
                    if event_date and not self._is_within_date_range(event_date, start_date, end_date):
                        logger.info(f"Event outside date range: {event_name}")
                        continue
                    
                    # Get location with None check
                    location_elements = element.find_elements(By.CLASS_NAME, "map-marker")
                    location = location_elements[0].text if location_elements and location_elements[0].text else ""
                    
                    # Create event object
                    event = {
                        "event_name": event_name,
                        "event_link": event_link or "",
                        "event_date": event_date,
                        "event_time": event_time,
                        "event_location": location,
                        "event_facilitators": "",
                        "event_registration_link": "",
                        "event_description": ""
                    }
                    
                    event_data.append(event)
                    logger.info(f"Successfully processed: {event_name}")
                    
                except (StaleElementReferenceException, NoSuchElementException) as e:
                    logger.warning(f"Element error for event {i+1}: {str(e)}")
                    continue
                except Exception as e:
                    logger.error(f"Unexpected error processing event {i+1}: {str(e)}")
                    continue
            
            logger.info(f"Successfully processed {len(event_data)} events")
            
            # Get additional details for each event
            for i, event in enumerate(event_data):
                try:
                    logger.info(f"Getting details for event {i+1}/{len(event_data)}: {event['event_name']}")
                    event = self._get_event_details(driver, event)
                except Exception as e:
                    logger.warning(f"Error getting details for {event['event_name']}: {str(e)}")
                    # Continue with basic event data
            
            return event_data
            
        except Exception as e:
            logger.error(f"Error in _scrape_events_from_url: {str(e)}")
            raise Exception(f"Failed to scrape events: {str(e)}")
            
        finally:
            # Always close the driver
            if driver:
                driver.quit()
         
            
    # Update your _get_event_details method with better error handling

    def _get_event_details(self, driver, event: Dict[str, Any]) -> Dict[str, Any]:
        """Visit the event detail page and extract additional information"""
        try:
            # Navigate to the event detail page
            event_link = event.get("event_link", "")
            if not event_link:
                logger.warning("No event link provided")
                return event
                
            logger.info(f"Navigating to: {event_link}")
            driver.get(event_link)
            
            # Wait for the page to load
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # Add a small delay
            time.sleep(1)
            
            # Get registration link if available
            try:
                reg_elements = driver.find_elements(By.CLASS_NAME, "lw_join_online")
                if reg_elements:
                    reg_element = reg_elements[0]
                    reg_link = reg_element.get_attribute("href")
                    if reg_link:
                        event["event_registration_link"] = reg_link
            except Exception as e:
                logger.warning(f"Error getting registration link: {e}")
            
            # Method 1: Try to get from the intro div
            try:
                intro_elements = driver.find_elements(By.CLASS_NAME, "intro")
                if intro_elements:
                    intro_div = intro_elements[0]
                    intro_text = intro_div.text
                    
                    if intro_text:  # Check if not None/empty
                        # Parse facilitator
                        facilitator_match = re.search(r'Facilitator[s]?:\s*(.*?)(?:\s*Description:|$)', intro_text, re.DOTALL)
                        if facilitator_match:
                            event["event_facilitators"] = facilitator_match.group(1).strip()
                        
                        # Parse description (from intro)
                        description_match = re.search(r'Description:\s*(.*?)$', intro_text, re.DOTALL)
                        if description_match:
                            event["event_description"] = description_match.group(1).strip()
            except Exception as e:
                logger.warning(f"Error parsing intro div: {e}")
            
            # Method 2: Try to get description from lw_calendar_event_description
            if not event.get("event_description"):
                try:
                    desc_elements = driver.find_elements(By.CLASS_NAME, "lw_calendar_event_description")
                    if desc_elements:
                        description_div = desc_elements[0]
                        desc_text = description_div.text
                        if desc_text:  # Check if not None/empty
                            event["event_description"] = desc_text.strip()
                except Exception as e:
                    logger.warning(f"Error getting description: {e}")
            
            # Method 3: If facilitator is still empty, try alternative parsing
            if not event.get("event_facilitators"):
                try:
                    body_element = driver.find_element(By.TAG_NAME, "body")
                    page_content = body_element.text if body_element else ""
                    
                    if page_content:  # Check if not None/empty
                        # Look for typical facilitator patterns
                        facilitator_patterns = [
                            r'Facilitator[s]?:\s*(.*?)(?:\n|Description:)',
                            r'Presenter[s]?:\s*(.*?)(?:\n|Description:)',
                            r'Instructor[s]?:\s*(.*?)(?:\n|Description:)'
                        ]
                        
                        for pattern in facilitator_patterns:
                            match = re.search(pattern, page_content, re.DOTALL)
                            if match:
                                event["event_facilitators"] = match.group(1).strip()
                                break
                except Exception as e:
                    logger.warning(f"Error in alternative facilitator parsing: {e}")
                    
        except Exception as e:
            logger.warning(f"Error getting details for {event.get('event_name', 'unknown')}: {str(e)}")
        
        return event